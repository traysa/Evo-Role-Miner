\newpage
\chapter{Experiments}
\label{sec:experiments}
The experiments with the EA Evo-RoleMiner provide information, which is not given in Saenko \& Kotenko \cite{saenko2012design}. In particular how parameters can be set and how the objectives of the role models evolve and impact other objectives. Afterwards the MOEA Evo-RoleMiner$M$ is tested and compared to the Evo-RoleMiner. Also the Evo-RoleMiner and Evo-RoleMiner$M$ are tested on datasets commonly used in role mining research.

This chapter describes the setup of the experiments executed. First the data sets used in the experiments are described. Then the setup and the results of the experiments are introduced. The experiments have been divided into several steps, where the results of one experiment lead to the setup of the experiments after. All experiments have been executed ten times and started with a random start-population.

In an initial series of experiments the objective measures introduced in section \ref{sec:optimizationCompleteness}, \ref{sec:optimizationComplexity} and \ref{sec:optimizationComprehension} are set as fitness function in the Evo-RoleMiner. This experiment series was executed to analyse the impact of these objectives to each other. It is shown that the objectives of minimizing confidentiality violations and minimizing availability violations can be conflicting.

In the second and third set of experiments the actual fitness functions for the Basic-RMP and Min-Edge-RMP (see section \ref{sec:fitnessFunctions}) are tested in the Evo-RoleMiner. In a later set of experiments the Evo-RoleMiner$M$ is tested as well as the inclusion of the interpretability measure (see section \ref{sec:classifierRule}) into the Evo-RoleMiner.

\section{Data Sets}
Datasets are the input access control policies for the role mining algorithm. They are provided as textfiles, which need to be parsed. They contain information on which user is assigned to which permission.
\subsection{Real Datasets}
In many research papers the same datasets are used for performance evaluation of role mining algorithms. Table \ref{tab:realDatasets} lists some of these data sets and their components. The authors of \cite{Ene} obtained these datasets from Cisco firewalls and the Lotus Domino server of the Hewlett Packard (HP) networks. The healthcare dataset was collected from the US Veteranâ€™s Administration.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|l|}
        \hline
        \rowcolor{myGray} 
        \textbf{Dataset} & \textbf{$|U|$} & \textbf{$|P|$} & \textbf{$|UPA|$} \\ \hline
        healthcare       & 46             & 46                   & 1486                                 \\ \hline
        domino           & 79             & 231                  & 730                                  \\ \hline
        emea             & 35             & 3046                 & 7220                                 \\ \hline
        apj              & 2044           & 1146                 & 6841                                 \\ \hline
        firewall-1       & 365            & 709                  & 31951                                \\ \hline
        firewall-2       & 325            & 590                  & 36428                                \\ \hline
        americas-small   & 3477           & 1587                 & 105205                               \\ \hline
    \end{tabular}
    \caption{Real Datasets used in Role Mining research. The table lists the amount of users, permissions and user-permission assignments in each dataset.}
    \label{tab:realDatasets}
\end{table}

\subsection{Synthetic Datasets}
The real dataset commonly used in Role Mining research (see Table \ref{tab:realDatasets}) do not provide user attribute information. Only Xu \& Stolter\cite{Xu} are generating synthetic attribute information on the given datasets. Also the data generators for synthetic datasets for role mining are only providing user-permission assignment information, but no user attribute information, e.g. in Vaidya et al.\cite{Vaidya:2006:RMR:1180405.1180424}.

In order to test smaller datasets with user attribute information a new synthetic data generator has been created for this thesis. The data generator allows to adjust, amongst other configurations, the dimensions of users and permissions, the density of user-permission assignments and user attribute information. The data generator is based on a reversed role-engineering process, which constructs an access control policy out of a role model. This allows to compare mined role models with the role model, the access control policy has been constructed on.

The data generator generates users, roles, user attribute rules for the roles, user-role matrix, role-permission matrix, user-permission matrix and a user-permission matrix with noise. A more detailed description of the data generator can be read in the Appendix \ref{sec:A_dataGenerator}.

Two datasets have been generated with the data generator in order to execute experiments with fitness functions $F_{basic\_INT}^{min}$ \eqref{eq:FBasicMin_INT} and $F_{edge\_INT}^{min}$ \eqref{eq:FEdgeMin_INT}. The synthetic datasets are listed in table \ref{tab:syntheticDatasets}.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \rowcolor{myGray} 
        \textbf{Dataset} & \textbf{$|U|$} & \textbf{$|P|$} & \textbf{$|UPA|$} & \textbf{$|R|$}\\ \hline
        1       & 10    & 10   & 42    & 4\\ \hline
        2       & 50    & 50   & 620   & 15\\ \hline
    \end{tabular}
    \caption{Synthetic Datasets}
    \label{tab:syntheticDatasets}
\end{table}

A visualization of Dataset1 and the Healthcare dataset can be seen in Figure \ref{fig:dataset1} and \ref{fig:healthcare}. Visualizations of the other real datasets can be seen in the Appendix \ref{sec:A_real_datasets}. Detailed information about the generated synthetic datasets can be found in Apendix \ref{sec:A_syn_datasets}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{dataset1}
    \caption{DATASET1: Role model of Dataset1 including User-Permission Matrix with 10 users and 10 permissions. From upper left to lower right: User-Role Matrix (Rows: Users, Columns: Roles), Role-Permission Matrix (Rows: Roles, Columns: Permissions), Resulting User-Permission Matrix used as input for the algorithm (Rows: Users, Columns: Permissions), User-Permission Matrix with Noise (Rows: Users, Columns: Permissions)}
    \label{fig:dataset1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{healthcare}
    \caption{HEALTHCARE DATASET: User-Permission Matrix with 46 users and 46 permissions.}
    \label{fig:healthcare}
\end{figure}

\import{chapters/}{10_Experiment1.tex}
\import{chapters/}{10_Experiment2.tex}
\import{chapters/}{10_Experiment3.tex}
\import{chapters/}{10_Experiment4.tex}
\import{chapters/}{10_Experiment5.tex}
\import{chapters/}{10_Experiment6.tex}
%\import{chapters/}{10_Experiment7.tex}

\section{Summary of Results}
In Experiment 2 it is shown that the Evo-RoleMiner for the Min-Edge-RMP (fitness function $F_{edge}^{min}$ \eqref{eq:FEdgeMin}) performs better than for the Basic-RMP ($F_{basic}^{min}$ \eqref{eq:FBasicMin}).

Experiment 3 demonstrates that parameter adjustments can reveal even better results. But the diversity of the role models in the population according role count gets very low after few generations and it is difficult for the Evo-RoleMiner to find a better solution since the search space gets limited to role models with a specific role count.

Experiment 4 demonstrates that a MOEA can help in the search since a wider solution space with role models of different role count is discovered. The completeness measure (confidentiality and availability violations) is well suited for the objectives in a MOEA, due to its conflicting complexity measure supporters: Higher vs. lower role count and assignment count (see Experiment 1). But the complexity measure has to be also an objective in order to remove unnecessary duplicate user-permission-assignments in the resulting role model (see section \ref{sec:exp_nsga2rweights}).

The individuals in the MOEA are more diverse regarding the role count compared to the individuals in the EA. The MOEA based on NSGA-II$R$\cite{Fortin:2013} performs better than the MOEA based on NSGA-II\cite{Deb:2002}. The MOEA based on NSGA-II$R$ is extended with a stochastic version of pareto dominance, which allows to set lower the selection pressure for the second objective\cite{clune2013evolutionary}.

In Experiment 5 it can not be demonstrated that the added interpretability measure improves the Evo-RoleMiner. The performance of the implemented rule induction is not good enough to be tested on bigger datasets with several user attribute information.

In Experiment 6 the Evo-RoleMiner$M$ is tested on the bigger Domino dataset and shows that the average time for one generation rises with the dimension of the dataset.