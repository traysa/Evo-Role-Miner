\newpage
\section{Background: Evolutionary algorithms (EAs)}
Evolutionary algorithms (EAs) are random searches inspired by the concept of the natural evolution. The general idea is to have a given population of individuals, which is evolving to new fitter generations of the population by natural selection (survival of the fittest). There are different variants of EAs: Genetic algorithms (GA), evolution strategies (ES), evolutionary programming (EP) and genetic programming (GP). All variants follow the same common concept described in the following with differences in technical details such as the representation of individuals\cite{Eiben}.\\
The individuals in a population represent candidate solutions for the problem. A fitness function is evaluating each candidate solution in the population. Candidate solutions with a high-rated fitness are more likely to be chosen to seed the next generation than candidate solutions with low-rated fitness. The next generation is generated by applying variation operators like recombination and mutation on the selected candidate solutions. Recombination is applied to two or more candidate solutions (parents) and result in one or more new candidate solutions (children). During the recombination new candidate solutions are generated by merging random parts of the parents. The mutation operator is applied on only one candidate solution. The output is a copy of the candidate solution, where a random part is changed. The new candidate solutions, which are the output of the variation operators, are called the offspring and compete with the candidate solutions in the current population for a spot in the next generation of the population. In a survival selection the candidate solutions for the next generation are chosen. This process is repeated until a sufficient candidate solution is found or a previously set limit (e.g. number of generations) is reached. A flow chart of an evolutionary algorithm process can be seen in figure \ref{fig:eaflowchart}.\\
\begin{figure}
    \centering
    \includegraphics[scale=0.08]{./Figures/eaflowchart.png}
    \rule{20em}{0.5pt}
    \caption{The general scheme of an evolutionary algorithm as a flow-chart \cite{Eiben}}
    \label{fig:eaflowchart}
\end{figure}
The driving forces of evolutionary algorithms are the variation operators, which are generating new diverse candidate solutions (novelty), and the natural selection, which is guiding to better candidate solutions (quality)\cite{Eiben}.\\
By preserving the possibility that candidate solutions with a lower fitness can be selected as seed for the offspring, the chance of getting into a local optimum should be minimized like in other meta-heuristics.\\

    \subsection{Components of Evolutionary Algorithms}
    An EA is defined by its components, procedures and operators, which will be introduced in the following.
    \begin{itemize}
        
        \item \textbf{Individuals}\\
        The individuals of a population in EA represent candidate solutions. The candidate solutions within the original problem context are called phenotypes, while their representation in the EA are called genotypes or chromosomes. A building block of a chromosome is called a gene, where the possible values for a gene are called alleles. The mapping from the phenotype to the genotype is called encoding and the inverse mapping is called decoding. A representation could be for example a binary string or a string with real values. Both also more complex structures could be the right representation. Finding the right representation of the phenotypes is problem-specific and a difficult task. It is crucial for the success of the EA. The representation influences the variation operators.
        
        \item \textbf{Population}\\
        The population is a a list of individuals (genotypes), which can occur several times within the list. The individuals are static objects, which do not change. The population is dynamic, which will change over time due to the exchange of individuals. The parent selection of the individuals, which will be the seed for the offspring, is mostly carried out on the whole population size. In most EAs the population size remains constant. The diversity of a population describes the measure of how many different individuals are present. The measure can be based on the fitness values, the phenotypes or the genotypes of the individuals. For example two individuals can represent two different phenotypes, but are evaluated with the same fitness value.\\
        The first population consists of randomly generated individuals or of chosen individuals with higher fitness.
        
        \item \textbf{Evaluation Function (or Fitness function)}\\
        The evaluation function evaluates the individuals of a population and assigned the fitness of a candidate solution. Since the fitness influences the selection of an individual, the evaluation function encourages improvements. The goal could be to minimize or to maximize the fitness of individuals. Mathematically a minimization function can be easily transformed to a maximization problem and vice versa. The evaluation function in an EA is constructed from the objective function in the phenotype space.
        
        \item \textbf{Parent Selection}\\
        The parent selection is the selection of individuals, which will be the seed for the next generation. Typically individuals with a better fitness value get more often selected to further improve the individuals. But also individuals with a low quality fitness get a chance to pass on their genes into the next generation. This ensures that the search is not too greedy and get into a local optimum. The balance between parents with a high-quality fitness and parents with a low-quality fitness is often probabilistic.
           
        \item \textbf{Variation Operators (Recombination and Mutation)}\\
        The variation operators are responsible for discovering the search space by creating new individuals on the bases of existing individuals in the current population. All newly created individuals of a generation is called the offspring.\\
        There are different types of variation operators. While the mutation oparator only takes one individual as input, the recombination (or crossover) operator takes at least two individuals as input. The mutation operator creates a new individual (mutant), which slightly differs from the input-individual (original). The change from the original to the mutant is chosen randomly. If the change is not random but rather guided, it is defined as an heuristic operator. The recombination operation is creating one or more new individuals (children) from its parent individuals by mixing randomly genes of these. A child might have a lower, equal or higher fitness value than its parents depending on the combination of genes.\\
        Variation operators are depending on the representation of the phenotypes.
        
        \item \textbf{Survivor Selection (Replacement)}\\
        The survivor selection is the replacement strategy of the population and happens after the creation of the offspring. The current population is replaced by a new population - the new generation - which is mostly the same size as the population, which is being replaced. Like in the parent selection, the selection is based on the fitness values of the individuals and is often deterministic. In a fitnesss-biased selection for example the individuals of the population and the offspring are sorted by their fitness values and then the top segment is selected for the next population generation. In an age-biased selection only the individuals from the offspring are considered for the new population generation. If the current fittest individual of a population is kept in the next population, the concept of elitism is used.
        
        \item \textbf{Termination Condition}\\
        The EA is either terminated when one individual is reaching a known optimal fitness value or when predefined computation conditions are met. These conditions can be for example the number of generations, number of fitness evaluations, maximum allowed CPU time or a threshold under which the population diversity has to fall.
    \end{itemize}
        
    \subsection{Multiobjective Evolutionary Algorithms (MOEAs)}
    The solution of an optimization problem might not only be measured regarding one objective but several, possibly conflicting objectives. These problems are called multiobjective problems (MOPs). It is unlikely that there is one optimal solution for such kind of problems. It is rather likely to have a set of optimal solutions also known as Pareto-optimal solutions.\\
    An example of a MOP could be buying an airplane ticket for a flight from city X to destination Y, where the buyer takes several factors into account. For simplification lets say the factors are price and travel time, where the rule is: The shorter the travel time, the higher the price. The buyer wants the cheapest airplane ticket and the shortest travel time, so he probably has to make a compromise between these two factors. There is a set of solutions for the two objective problem: From cheap long-travel to expensive short-travel solution. The graph in figure \ref{fig:paretoExample} demonstrates the different options and outlines the set of pareto-optimal solutions on the so-called Pareto Front. The buyer can pick one of the cheaper solutions, but has to make a trade-off regarding the travel-time.\\
    \begin{figure}
        \centering
        \includegraphics[scale=0.5]{./Figures/Pareto-Example.png}
        \rule{20em}{0.5pt}
        \caption{MOP Example: Buying an airplane ticket for a flight from X to Y with the objectives price and travel-time. A dot represents an offer from an airline. The red dots represents the optimal offers regarding the objectives, while the yellow dots are suboptimal offers.}
        \label{fig:paretoExample}
    \end{figure}
    The fitness values of several objectives can also be combined in one single objective function, where the fitness values for each objective are weighted. This approach is also called scalarisation\cite{Eiben}. The weights have to be pre-determined and adjust the preference of an objective. Sometimes these preferences are not known beforehand. This is where multiobjective optimization approaches become interesting.\\
    The goal in multiobjective optimization is to find all pareto-optimal solutions. The strength of EAs can be seen in solving MOPs. An EA can find several pareto-optimal solutions in one single run, since it works with a population of solutions simultaneously\cite{Deb:2002}.\\
    \hl{Why do I use MOEA this in my thesis??}
    \subsubsection{Nondominated Sorting Genetic Algorithm II (NSGA-II)}
    One EA approach to multiobjective Optimization is the nondominated sorting genetic algorithm II (NSGA-II)\cite{Deb:2002}.\\
    \hl{First find argumentation why you do MOEA on your domain}
    
    \subsection{Co-Evolution}
    \hl{SECTION UNDER CONSTRUCTION}\\
    A special form of evolution in EAs is co-evolution. In co-evolution several separate populations are influencing the fitness of the individuals of each other.
    
    \subsubsection{Symbiotic, Adaptive Neuro-Evolution (SANE)}
    \hl{Results not good enough}
    
    \subsubsection{Enforced Sub-Populations (ESP)}
    \hl{Not implemented8
    
    \subsection{Human interaction}
    \hl{Not implemented}